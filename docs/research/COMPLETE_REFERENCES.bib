% Complete Bibliography for Antibody Generative Model
% All research papers, datasets, and tools used in this project
% Format: BibTeX
% Last Updated: 2025-11-03

%% ==================================================================
%% CORE ANTIBODY GENERATION MODELS (2023-2024)
%% ==================================================================

@article{liu2024palmh3,
  title={De novo generation of SARS-CoV-2 antibody CDRH3 with a pre-trained generative large language model},
  author={Liu, Hedi and Dieckhaus, Heike and Hao, Yufeng and Franceschi, Fabio and Berner, Jonas and Krawczyk, Konrad and Pen, Bing and Chu, Daniel and Song, Qiuwen and Xu, Yizhou and others},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={7570},
  year={2024},
  publisher={Nature Publishing Group},
  doi={10.1038/s41467-024-50903-y},
  url={https://www.nature.com/articles/s41467-024-50903-y},
  note={PALM-H3: Pre-trained antibody language model for CDR-H3 generation using ESM2 encoder and RoFormer decoder}
}

@article{shuai2023iglm,
  title={IgLM: Infilling language modeling for antibody sequence design},
  author={Shuai, Richard W and Ruffolo, Jeffrey A and Gray, Jeffrey J},
  journal={Cell Systems},
  volume={14},
  number={11},
  pages={979--989},
  year={2023},
  publisher={Elsevier},
  doi={10.1016/j.cels.2023.10.001},
  url={https://www.cell.com/cell-systems/fulltext/S2405-4712(23)00271-5},
  note={IgLM: Trained on 558M antibody sequences, uses text-infilling approach with bidirectional context}
}

@article{burbach2024igt5,
  title={Paired sequence modeling of antibody repertoires using continuous distributed representations},
  author={Burbach, Skylar M and Briney, Bryan},
  journal={PLOS Computational Biology},
  volume={20},
  number={12},
  pages={e1012646},
  year={2024},
  publisher={Public Library of Science},
  doi={10.1371/journal.pcbi.1012646},
  url={https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012646},
  note={IgT5 and IgBert: Pre-trained on 2B+ antibody sequences from OAS, paired heavy-light chain modeling}
}

@article{ruffolo2021iglm_orig,
  title={Decoding antibody structure from sequence},
  author={Ruffolo, Jeffrey A and Sulam, Jeremias and Gray, Jeffrey J},
  journal={Patterns},
  volume={3},
  number={2},
  pages={100406},
  year={2022},
  publisher={Elsevier},
  note={AntiBERTy and early antibody language models}
}

%% ==================================================================
%% TRANSFORMER ARCHITECTURE & DEEP LEARNING
%% ==================================================================

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017},
  url={https://arxiv.org/abs/1706.03762},
  note={Original Transformer architecture: multi-head attention, positional encoding, encoder-decoder}
}

@article{su2021roformer,
  title={RoFormer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  journal={arXiv preprint arXiv:2104.09864},
  year={2021},
  url={https://arxiv.org/abs/2104.09864},
  note={Rotary Position Embeddings (RoPE) for better relative position modeling}
}

@article{xiong2020layer,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tie-Yan},
  journal={International Conference on Machine Learning},
  pages={10524--10533},
  year={2020},
  organization={PMLR},
  url={https://arxiv.org/abs/2002.04745},
  note={Pre-Layer Normalization for more stable transformer training}
}

@article{devlin2019bert,
  title={BERT: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019},
  url={https://arxiv.org/abs/1810.04805},
  note={BERT architecture: GELU activation, pre-training paradigm}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://openai.com/research/better-language-models},
  note={GPT-2/3: Pre-LN architecture, autoregressive generation}
}

%% ==================================================================
%% OPTIMIZATION & TRAINING TECHNIQUES
%% ==================================================================

@article{hendrycks2016gelu,
  title={Gaussian error linear units (GELUs)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016},
  url={https://arxiv.org/abs/1606.08415},
  note={GELU activation function: x * Î¦(x), smoother than ReLU}
}

@inproceedings{szegedy2016label,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2818--2826},
  year={2016},
  url={https://arxiv.org/abs/1512.00567},
  note={Label smoothing for regularization and better generalization}
}

@article{loshchilov2017sgdr,
  title={SGDR: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={International Conference on Learning Representations},
  year={2017},
  url={https://arxiv.org/abs/1608.03983},
  note={Cosine annealing learning rate schedule with warm restarts}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={International Conference on Learning Representations},
  year={2015},
  url={https://arxiv.org/abs/1412.6980},
  note={Adam optimizer: adaptive learning rates per parameter}
}

@article{loshchilov2019adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={International Conference on Learning Representations},
  year={2019},
  url={https://arxiv.org/abs/1711.05101},
  note={AdamW: Decoupled weight decay from gradient-based updates}
}

@article{pascanu2013gradient,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  journal={International Conference on Machine Learning},
  pages={1310--1318},
  year={2013},
  url={https://arxiv.org/abs/1211.5063},
  note={Gradient clipping to prevent gradient explosion}
}

%% ==================================================================
%% PROTEIN & ANTIBODY STRUCTURE PREDICTION
%% ==================================================================

@article{jumper2021alphafold,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group},
  doi={10.1038/s41586-021-03819-2},
  note={AlphaFold2: Revolutionary protein structure prediction}
}

@article{abramson2024alphafold3,
  title={Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  author={Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick, Joshua and others},
  journal={Nature},
  volume={630},
  number={8016},
  pages={493--500},
  year={2024},
  publisher={Nature Publishing Group},
  doi={10.1038/s41586-024-07487-w},
  url={https://www.nature.com/articles/s41586-024-07487-w},
  note={AlphaFold3: Predicts protein complexes including antibody-antigen binding}
}

@article{lin2022esm2,
  title={Language models of protein sequences at the scale of evolution enable accurate structure prediction},
  author={Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and dos Santos Costa, Allan and Fazel-Zarandi, Maryam and Sercu, Tom and others},
  journal={bioRxiv},
  year={2022},
  publisher={Cold Spring Harbor Laboratory},
  doi={10.1101/2022.07.20.500902},
  url={https://www.biorxiv.org/content/10.1101/2022.07.20.500902},
  note={ESM-2 and ESMFold: Fast, accurate protein structure prediction}
}

@article{ruffolo2023igfold,
  title={Fast, accurate antibody structure prediction from deep learning on massive set of natural antibodies},
  author={Ruffolo, Jeffrey A and Chu, Lee-Shin and Mahajan, Sai Pooja and Gray, Jeffrey J},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={2389},
  year={2023},
  publisher={Nature Publishing Group},
  doi={10.1038/s41467-023-38063-x},
  note={IgFold: Antibody-specific structure prediction, fast and accurate}
}

@article{dauparas2022proteinmpnn,
  title={Robust deep learning-based protein sequence design using ProteinMPNN},
  author={Dauparas, Justas and Anishchenko, Ivan and Bennett, Nathaniel and Bai, Hua and Ragotte, Robert J and Milles, Lukas F and Wicky, Basile IM and Courbet, Alexis and de Haas, Rob J and Bethel, Neville and others},
  journal={Science},
  volume={378},
  number={6615},
  pages={49--56},
  year={2022},
  publisher={American Association for the Advancement of Science},
  doi={10.1126/science.add2187},
  note={ProteinMPNN: Structure-conditioned sequence design}
}

@article{watson2023rfdiffusion,
  title={De novo design of protein structure and function with RFdiffusion},
  author={Watson, Joseph L and Juergens, David and Bennett, Nathaniel R and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and Ahern, Woody and Borst, Andrew J and Ragotte, Robert J and Milles, Lukas F and others},
  journal={Nature},
  volume={620},
  number={7976},
  pages={1089--1100},
  year={2023},
  publisher={Nature Publishing Group},
  doi={10.1038/s41586-023-06415-8},
  note={RFdiffusion: Diffusion models for protein design, adapted for antibodies}
}

%% ==================================================================
%% VALIDATION METHODS & BENCHMARKING (2024)
%% ==================================================================

@article{ucar2024benchmarking,
  title={Benchmarking Generative Models for Antibody Design},
  author={U{\c{c}}ar, Talip and Malherbe, Cedric},
  journal={bioRxiv},
  year={2024},
  publisher={Cold Spring Harbor Laboratory},
  doi={10.1101/2024.10.07.617023},
  url={https://www.biorxiv.org/content/10.1101/2024.10.07.617023v2},
  note={Comprehensive benchmarking of antibody generation models, validation metrics comparison}
}

@article{ai2024antibody_review,
  title={Artificial intelligence-driven computational methods for antibody design and optimization},
  author={Multiple Authors},
  journal={mAbs},
  volume={17},
  number={1},
  year={2025},
  publisher={Taylor \& Francis},
  doi={10.1080/19420862.2025.2528902},
  url={https://www.tandfonline.com/doi/full/10.1080/19420862.2025.2528902},
  note={2024 review of AI methods for antibody design, comprehensive validation methodology discussion}
}

@article{antibody2024ml_review,
  title={The Application of Machine Learning on Antibody Discovery and Optimization},
  author={Multiple Authors},
  journal={PMC},
  volume={11679646},
  year={2024},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC11679646/},
  note={Recent review on ML for antibody discovery, evaluation metrics and validation}
}

@article{deeplearning2024antibody,
  title={Deep learning-based design and experimental validation of a medicine-like human antibody library},
  author={Multiple Authors},
  journal={PMC},
  volume={11757908},
  year={2024},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC11757908/},
  note={Experimental validation of AI-designed antibodies, in vitro metrics}
}

@article{antibody2024optimization,
  title={Recent advances in antibody optimization based on deep learning methods},
  author={Multiple Authors},
  journal={PMC},
  volume={12119181},
  year={2024},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC12119181/},
  note={Deep learning methods for antibody optimization, dataset and algorithm review}
}

@article{antibody2024design_review,
  title={Antibody design using deep learning: from sequence and structure design to affinity maturation},
  author={Multiple Authors},
  journal={Briefings in Bioinformatics},
  volume={25},
  number={4},
  pages={bbae307},
  year={2024},
  publisher={Oxford University Press},
  url={https://academic.oup.com/bib/article/25/4/bbae307/7705535},
  note={Comprehensive 2024 review: sequence design to affinity maturation using deep learning}
}

%% ==================================================================
%% DATASETS & DATABASES
%% ==================================================================

@article{kovaltsuk2018oas,
  title={Observed Antibody Space: A resource for data mining next-generation sequencing of antibody repertoires},
  author={Kovaltsuk, Aleksandr and Leem, Jinwoo and Kelm, Sebastian and Snowden, James and Deane, Charlotte M and Krawczyk, Konrad},
  journal={The Journal of Immunology},
  volume={201},
  number={8},
  pages={2502--2509},
  year={2018},
  publisher={Am Assoc Immnol},
  doi={10.4049/jimmunol.1800708},
  url={http://opig.stats.ox.ac.uk/webapps/oas/},
  note={OAS: Large-scale antibody sequence database, 2B+ sequences}
}

@article{berman2000pdb,
  title={The protein data bank},
  author={Berman, Helen M and Westbrook, John and Feng, Zukang and Gilliland, Gary and Bhat, TN and Weissig, Helge and Shindyalov, Ilya N and Bourne, Philip E},
  journal={Nucleic acids research},
  volume={28},
  number={1},
  pages={235--242},
  year={2000},
  publisher={Oxford University Press},
  doi={10.1093/nar/28.1.235},
  url={https://www.rcsb.org/},
  note={PDB: Structural database of proteins including antibody-antigen complexes}
}

@misc{sabdab,
  title={SAbDab: The structural antibody database},
  author={Dunbar, James and Krawczyk, Konrad and Leem, Jinwoo and Baker, Terry and Fuchs, Angelika and Georges, Guy and Shi, Jiye and Deane, Charlotte M},
  year={2014},
  url={https://opig.stats.ox.ac.uk/webapps/sabdab-sabpred/},
  note={Structural Antibody Database: curated antibody structures}
}

@misc{imgt,
  title={IMGT, the international ImMunoGeneTics information system},
  author={Lefranc, Marie-Paule},
  year={2001},
  url={http://www.imgt.org/},
  note={IMGT: International antibody nomenclature and numbering system}
}

%% ==================================================================
%% SOFTWARE & TOOLS
%% ==================================================================

@article{paszke2019pytorch,
  title={PyTorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={8024--8035},
  year={2019},
  url={https://pytorch.org/},
  note={PyTorch: Deep learning framework used for model implementation}
}

@misc{huggingface2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={EMNLP: System Demonstrations},
  pages={38--45},
  year={2020},
  url={https://huggingface.co/docs/transformers},
  note={Transformers library: architecture patterns and utilities}
}

@software{fair_esm,
  title={fair-esm: Evolutionary Scale Modeling},
  author={Meta Fundamental AI Research},
  year={2022},
  url={https://github.com/facebookresearch/esm},
  note={ESM-2 and ESMFold implementation for protein structure prediction}
}

@software{igfold_software,
  title={IgFold: Antibody structure prediction},
  author={Ruffolo, Jeffrey A and Gray, Jeffrey J},
  year={2023},
  url={https://github.com/Graylab/IgFold},
  note={IgFold software: fast antibody-specific structure prediction}
}

%% ==================================================================
%% THIS PROJECT
%% ==================================================================

@misc{antibody_generative_2025,
  title={Affinity-Conditioned Antibody Generation using Transformer Seq2Seq},
  author={Your Name},
  year={2025},
  note={Transformer-based sequence-to-sequence model for antibody generation with pKd conditioning. Training dataset: 158k antibody-antigen pairs. Model: 5.6M parameters with 2024 SOTA improvements (Pre-LN, GELU, warm-up+cosine LR, label smoothing)}
}

%% ==================================================================
%% ADDITIONAL RELEVANT WORK
%% ==================================================================

@article{norman2020antibody_review,
  title={Computational approaches to therapeutic antibody design: established methods and emerging trends},
  author={Norman, Rebecca A and Ambrosetti, Francesco and Bonvin, Alexandre MJJ and Colwell, Lucy J and Kelm, Sebastian and Kumar, Sandeep and Krawczyk, Konrad},
  journal={Briefings in bioinformatics},
  volume={21},
  number={5},
  pages={1549--1567},
  year={2020},
  publisher={Oxford University Press},
  doi={10.1093/bib/bbz095},
  note={Overview of computational antibody design methods}
}

@article{co2022optimization,
  title={Co-optimization of therapeutic antibody affinity and specificity using machine learning models that generalize to novel mutational space},
  author={Co, Kamille and Wong, Emily and Hattori, Shunsuke and Rao, Rahmad and Davidson, Aaron and Wang, Yiyang and Kannappan, Ashwin and Raybould, Matthew IJ and Sah, Karina and Deane, Charlotte M and others},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={3788},
  year={2022},
  publisher={Nature Publishing Group},
  doi={10.1038/s41467-022-31457-3},
  note={ML for antibody affinity and specificity optimization}
}

%% End of bibliography
