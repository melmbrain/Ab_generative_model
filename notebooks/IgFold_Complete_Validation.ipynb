{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antibody Validation with IgFold on Google Colab\n",
    "\n",
    "Complete pipeline for validating antibody generation models using IgFold.\n",
    "\n",
    "**Setup:** Enable GPU (Runtime â†’ Change runtime type â†’ GPU)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ No GPU found!\")\n",
    "    print(\"\\nâš ï¸ IMPORTANT: Enable GPU in Runtime â†’ Change runtime type â†’ GPU (T4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies\n",
    "\n",
    "**IMPORTANT:** After running this cell, you MUST restart the runtime!\n",
    "- Click: `Runtime â†’ Restart runtime`\n",
    "- Then re-run Cell 1\n",
    "- Skip this cell after restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing IgFold with compatible dependencies...\")\n",
    "print(\"This may take 3-4 minutes...\\n\")\n",
    "\n",
    "# Step 1: Clean uninstall\n",
    "print(\"Step 1: Cleaning old packages...\")\n",
    "!pip uninstall -y -q torch torchvision torchaudio transformers accelerate huggingface_hub\n",
    "\n",
    "# Step 2: Install PyTorch 2.5\n",
    "print(\"Step 2: Installing PyTorch 2.5...\")\n",
    "!pip install -q torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Step 3: Install compatible huggingface-hub\n",
    "print(\"Step 3: Installing huggingface-hub...\")\n",
    "!pip install -q huggingface-hub==0.17.3\n",
    "\n",
    "# Step 4: Install transformers\n",
    "print(\"Step 4: Installing transformers...\")\n",
    "!pip install -q transformers==4.35.0\n",
    "\n",
    "# Step 5: Install accelerate\n",
    "print(\"Step 5: Installing accelerate...\")\n",
    "!pip install -q accelerate==0.20.3\n",
    "\n",
    "# Step 6: Install IgFold\n",
    "print(\"Step 6: Installing IgFold...\")\n",
    "!pip install -q igfold\n",
    "\n",
    "print(\"\\nâœ… Installation complete!\")\n",
    "print(\"\\nâš ï¸ CRITICAL: You MUST restart the runtime now!\")\n",
    "print(\"   1. Click: Runtime â†’ Restart runtime\")\n",
    "print(\"   2. Re-run Cell 1 (GPU check)\")\n",
    "print(\"   3. Then run Cell 3 (skip Cell 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test IgFold with Sample Antibody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igfold import IgFoldRunner\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "print(\"Initializing IgFold...\")\n",
    "igfold = IgFoldRunner()\n",
    "print(\"âœ… IgFold loaded!\\n\")\n",
    "\n",
    "# Test with a sample antibody\n",
    "heavy = \"EVQLVESGGGLVQPGGSLRLSCAASGFTISDYAIHWVRQAPGKGLEWVAGITPAGGYTAYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARFVFFLPYAMDYWGQGTLVTVSS\"\n",
    "light = \"DIQMTQSPSSLSASVGDRVTITCRASQDVSTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSGSGTDFTLTISSSLQPEDFATYCQQSYTTPPTFGQGTKVEIKR\"\n",
    "\n",
    "print(f\"Testing with sample antibody:\")\n",
    "print(f\"  Heavy: {len(heavy)} aa\")\n",
    "print(f\"  Light: {len(light)} aa\")\n",
    "print(\"\\nPredicting structure... (this may take 30-60 seconds)\")\n",
    "\n",
    "# Create temp file for output\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.pdb', delete=False) as tmp:\n",
    "    pdb_file = tmp.name\n",
    "\n",
    "# Run IgFold\n",
    "sequences = {'H': heavy, 'L': light}\n",
    "igfold.fold(pdb_file=pdb_file, sequences=sequences, do_refine=False, do_renum=False)\n",
    "\n",
    "# Read PDB and extract pLDDT\n",
    "with open(pdb_file, 'r') as f:\n",
    "    pdb_string = f.read()\n",
    "\n",
    "# Extract pLDDT scores from B-factor column\n",
    "plddt_scores = []\n",
    "for line in pdb_string.split('\\n'):\n",
    "    if line.startswith('ATOM'):\n",
    "        try:\n",
    "            bfactor = float(line[60:66].strip())\n",
    "            plddt_scores.append(bfactor)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "plddt_scores = np.array(plddt_scores)\n",
    "\n",
    "# Convert from fraction (0-1) to percentage (0-100) and clip outliers\n",
    "plddt_scores = np.clip(plddt_scores * 100, 0, 100)\n",
    "\n",
    "mean_plddt = plddt_scores.mean()\n",
    "\n",
    "print(f\"\\nâœ… Structure predicted!\")\n",
    "print(f\"   Mean pLDDT: {mean_plddt:.2f}\")\n",
    "print(f\"   Min pLDDT:  {plddt_scores.min():.2f}\")\n",
    "print(f\"   Max pLDDT:  {plddt_scores.max():.2f}\")\n",
    "\n",
    "if mean_plddt > 70:\n",
    "    print(\"\\nðŸŽ‰ Good quality structure!\")\n",
    "elif mean_plddt > 50:\n",
    "    print(\"\\nâœ… Fair quality structure\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Lower quality structure\")\n",
    "\n",
    "# Save the PDB file\n",
    "with open('test_antibody.pdb', 'w') as f:\n",
    "    f.write(pdb_string)\n",
    "    \n",
    "print(\"\\nPDB file saved as: test_antibody.pdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Test PDB Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading PDB file...\")\n",
    "files.download('test_antibody.pdb')\n",
    "print(\"\\nâœ… Download complete!\")\n",
    "print(\"You can view this in PyMOL, ChimeraX, or https://www.rcsb.org/3d-view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation Function for Multiple Antibodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_antibodies(antibody_sequences, save_pdbs=True):\n",
    "    \"\"\"\n",
    "    Validate a list of antibody sequences using IgFold.\n",
    "    \n",
    "    Args:\n",
    "        antibody_sequences: List of tuples (heavy_chain, light_chain)\n",
    "        save_pdbs: Whether to save PDB files\n",
    "    \n",
    "    Returns:\n",
    "        List of validation results\n",
    "    \"\"\"\n",
    "    from igfold import IgFoldRunner\n",
    "    import tempfile\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    print(f\"Validating {len(antibody_sequences)} antibodies...\\n\")\n",
    "    \n",
    "    # Initialize IgFold\n",
    "    igfold = IgFoldRunner()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (heavy, light) in enumerate(antibody_sequences):\n",
    "        print(f\"[{i+1}/{len(antibody_sequences)}] Processing antibody {i+1}...\")\n",
    "        \n",
    "        try:\n",
    "            # Create temp file\n",
    "            with tempfile.NamedTemporaryFile(mode='w', suffix='.pdb', delete=False) as tmp:\n",
    "                pdb_file = tmp.name\n",
    "            \n",
    "            # Run IgFold\n",
    "            sequences = {'H': heavy, 'L': light}\n",
    "            igfold.fold(pdb_file=pdb_file, sequences=sequences, do_refine=False, do_renum=False)\n",
    "            \n",
    "            # Read PDB\n",
    "            with open(pdb_file, 'r') as f:\n",
    "                pdb_string = f.read()\n",
    "            \n",
    "            # Extract pLDDT\n",
    "            plddt_scores = []\n",
    "            for line in pdb_string.split('\\n'):\n",
    "                if line.startswith('ATOM'):\n",
    "                    try:\n",
    "                        bfactor = float(line[60:66].strip())\n",
    "                        plddt_scores.append(bfactor)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            plddt_scores = np.array(plddt_scores)\n",
    "            \n",
    "            # Convert from fraction (0-1) to percentage (0-100) and clip outliers\n",
    "            plddt_scores = np.clip(plddt_scores * 100, 0, 100)\n",
    "            \n",
    "            mean_plddt = float(plddt_scores.mean())\n",
    "            \n",
    "            # Quality grade\n",
    "            if mean_plddt > 90:\n",
    "                quality = \"Excellent\"\n",
    "            elif mean_plddt > 70:\n",
    "                quality = \"Good\"\n",
    "            elif mean_plddt > 50:\n",
    "                quality = \"Fair\"\n",
    "            else:\n",
    "                quality = \"Poor\"\n",
    "            \n",
    "            result = {\n",
    "                'antibody_id': i,\n",
    "                'heavy_length': len(heavy),\n",
    "                'light_length': len(light),\n",
    "                'mean_plddt': mean_plddt,\n",
    "                'min_plddt': float(plddt_scores.min()),\n",
    "                'max_plddt': float(plddt_scores.max()),\n",
    "                'quality': quality\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            # Save PDB\n",
    "            if save_pdbs:\n",
    "                pdb_filename = f'antibody_{i:03d}_plddt{mean_plddt:.0f}.pdb'\n",
    "                with open(pdb_filename, 'w') as f:\n",
    "                    f.write(pdb_string)\n",
    "            \n",
    "            print(f\"    pLDDT: {mean_plddt:.1f} - {quality}\")\n",
    "            \n",
    "            # Clean up temp file\n",
    "            os.unlink(pdb_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ Error: {e}\")\n",
    "            results.append({'antibody_id': i, 'error': str(e)})\n",
    "    \n",
    "    # Summary\n",
    "    valid_results = [r for r in results if 'error' not in r]\n",
    "    if valid_results:\n",
    "        plddt_values = [r['mean_plddt'] for r in valid_results]\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"Validation Summary\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total antibodies:     {len(antibody_sequences)}\")\n",
    "        print(f\"Successful:           {len(valid_results)}\")\n",
    "        print(f\"Failed:               {len(antibody_sequences) - len(valid_results)}\")\n",
    "        print(f\"\\nMean pLDDT:           {np.mean(plddt_values):.2f} Â± {np.std(plddt_values):.2f}\")\n",
    "        print(f\"Median pLDDT:         {np.median(plddt_values):.2f}\")\n",
    "        print(f\"Range:                {np.min(plddt_values):.2f} - {np.max(plddt_values):.2f}\")\n",
    "        print(\"\\nQuality Distribution:\")\n",
    "        print(f\"  Excellent (>90):    {sum(1 for p in plddt_values if p > 90)} ({sum(1 for p in plddt_values if p > 90)/len(plddt_values)*100:.1f}%)\")\n",
    "        print(f\"  Good (70-90):       {sum(1 for p in plddt_values if 70 < p <= 90)} ({sum(1 for p in plddt_values if 70 < p <= 90)/len(plddt_values)*100:.1f}%)\")\n",
    "        print(f\"  Fair (50-70):       {sum(1 for p in plddt_values if 50 < p <= 70)} ({sum(1 for p in plddt_values if 50 < p <= 70)/len(plddt_values)*100:.1f}%)\")\n",
    "        print(f\"  Poor (<50):         {sum(1 for p in plddt_values if p <= 50)} ({sum(1 for p in plddt_values if p <= 50)/len(plddt_values)*100:.1f}%)\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Validation function ready!\")\n",
    "print(\"\\nUsage:\")\n",
    "print('  antibodies = [(heavy1, light1), (heavy2, light2), ...]')\n",
    "print('  results = validate_antibodies(antibodies)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Option A: Validate Custom Antibody Sequences\n",
    "\n",
    "Replace the sequences below with your own antibodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your generated antibodies\n",
    "my_antibodies = [\n",
    "    (\n",
    "        \"EVQLVESGGGLVQPGGSLRLSCAASGFTISDYAIHWVRQAPGKGLEWVAGITPAGGYTAYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARFVFFLPYAMDYWGQGTLVTVSS\",\n",
    "        \"DIQMTQSPSSLSASVGDRVTITCRASQDVSTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSGSGTDFTLTISSSLQPEDFATYCQQSYTTPPTFGQGTKVEIKR\"\n",
    "    ),\n",
    "    # Add more antibodies here...\n",
    "]\n",
    "\n",
    "# Run validation\n",
    "results = validate_antibodies(my_antibodies, save_pdbs=True)\n",
    "\n",
    "# Display results as table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([r for r in results if 'error' not in r])\n",
    "print(\"\\nðŸ“Š Detailed Results:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Option B: Upload Model and Generate Antibodies\n",
    "\n",
    "### 7a. Upload Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your model checkpoint file:\")\n",
    "print(\"File: improved_small_2025_10_31_best.pt (~100MB)\")\n",
    "print(\"\\nClick 'Choose Files' below...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "checkpoint_name = list(uploaded.keys())[0]\n",
    "print(f\"\\nâœ… Uploaded: {checkpoint_name}\")\n",
    "print(f\"   Size: {os.path.getsize(checkpoint_name) / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Upload Model Code Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create generators directory\n",
    "!mkdir -p generators\n",
    "\n",
    "print(\"Upload your model code files (3 files):\")\n",
    "print(\"1. transformer_seq2seq.py\")\n",
    "print(\"2. tokenizer.py\")\n",
    "print(\"3. data_loader.py\")\n",
    "print(\"\\nClick 'Choose Files' below...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move files to generators directory\n",
    "for filename in uploaded.keys():\n",
    "    shutil.move(filename, f'generators/{filename}')\n",
    "    print(f\"âœ… Moved {filename} to generators/\")\n",
    "\n",
    "print(\"\\nâœ… All model files uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c. Generate Antibodies from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from generators.transformer_seq2seq import create_model\n",
    "from generators.tokenizer import AminoAcidTokenizer\n",
    "\n",
    "print(\"Loading model and generating antibodies...\\n\")\n",
    "\n",
    "# Sample antigens for generation\n",
    "test_antigens = [\n",
    "    \"MKTIIALSYIFCLVFADYKDDDDK\",\n",
    "    \"MKLLILTCLVAVSARAGVEFEGSGA\",\n",
    "    \"MNGLKRKTGKVMSKKFTVGLMAMLPT\",\n",
    "    \"MKLVVLSLSLVLALILQGVNAFGGGS\",\n",
    "    \"MKFLVNVALVFMVVYISYIYAAGSQ\",\n",
    "    \"MGAASGRRGPGLLLPLPLLLLLPPQEAL\",\n",
    "    \"MKLGIWLALAGLVLAFSQYAFGQG\",\n",
    "    \"MLLSVPLLLGLLGLAAADQGVVPR\",\n",
    "    \"MKWVTFISLLFLFSSAYSRGVFRRD\",\n",
    "    \"MGLSDGEWQLVLNVWGKVEADI\"\n",
    "]\n",
    "\n",
    "test_pkds = [8.0, 9.0, 7.5, 8.5, 9.5, 8.0, 7.0, 8.5, 9.0, 7.5]  # Target binding affinities\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AminoAcidTokenizer()\n",
    "print(f\"âœ… Tokenizer loaded (vocab size: {tokenizer.vocab_size})\")\n",
    "\n",
    "# Create and load model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = create_model('small', vocab_size=tokenizer.vocab_size, max_src_len=512, max_tgt_len=300)\n",
    "model = model.to(device)\n",
    "print(f\"âœ… Model created ({model.get_model_size():,} parameters)\")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_name, map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(f\"âœ… Checkpoint loaded (epoch {checkpoint['epoch']}, val loss {checkpoint['val_loss']:.4f})\")\n",
    "\n",
    "# Generate antibodies\n",
    "print(f\"\\nðŸ”¬ Generating {len(test_antigens)} antibodies...\\n\")\n",
    "generated_antibodies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (antigen_seq, target_pkd) in enumerate(zip(test_antigens, test_pkds)):\n",
    "        # Tokenize antigen\n",
    "        antigen_tokens = tokenizer.encode(antigen_seq)\n",
    "        if len(antigen_tokens) > 512:\n",
    "            antigen_tokens = antigen_tokens[:512]\n",
    "        src = torch.tensor([antigen_tokens]).to(device)\n",
    "        pkd = torch.tensor([[target_pkd]]).float().to(device)\n",
    "        \n",
    "        # Generate\n",
    "        generated = model.generate_greedy(src, pkd, max_length=300)\n",
    "        antibody_seq = tokenizer.decode(generated[0].cpu().tolist())\n",
    "        \n",
    "        # Split heavy and light chains\n",
    "        if '|' in antibody_seq:\n",
    "            heavy, light = antibody_seq.split('|', 1)\n",
    "        else:\n",
    "            heavy = antibody_seq[:120]\n",
    "            light = antibody_seq[120:]\n",
    "        \n",
    "        generated_antibodies.append((heavy, light))\n",
    "        \n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"   Generated {i + 1}/{len(test_antigens)}\")\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(generated_antibodies)} antibodies!\")\n",
    "print(f\"   Average heavy chain length: {sum(len(h) for h, l in generated_antibodies) / len(generated_antibodies):.1f} aa\")\n",
    "print(f\"   Average light chain length: {sum(len(l) for h, l in generated_antibodies) / len(generated_antibodies):.1f} aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d. Validate Generated Antibodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the generated antibodies\n",
    "results = validate_antibodies(generated_antibodies, save_pdbs=True)\n",
    "\n",
    "# Display results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([r for r in results if 'error' not in r])\n",
    "print(\"\\nðŸ“Š Detailed Results:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download All PDB Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Create zip file with all PDB structures\n",
    "pdb_files = [f for f in os.listdir('.') if f.endswith('.pdb')]\n",
    "\n",
    "if pdb_files:\n",
    "    with zipfile.ZipFile('antibody_structures.zip', 'w') as zipf:\n",
    "        for pdb_file in pdb_files:\n",
    "            zipf.write(pdb_file)\n",
    "    \n",
    "    print(f\"Created zip file with {len(pdb_files)} PDB structures\")\n",
    "    \n",
    "    # Download\n",
    "    files.download('antibody_structures.zip')\n",
    "    print(\"\\nâœ… Download complete!\")\n",
    "else:\n",
    "    print(\"No PDB files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What this notebook does:**\n",
    "- âœ… Uses Google Colab's FREE GPU (T4 with 16GB VRAM)\n",
    "- âœ… Installs IgFold with all dependencies\n",
    "- âœ… Fixed pLDDT extraction (proper 0-100 scores)\n",
    "- âœ… Validates antibody structures\n",
    "- âœ… Generates antibodies from your trained model\n",
    "- âœ… Saves PDB structure files\n",
    "- âœ… Downloads results to your computer\n",
    "\n",
    "**Usage:**\n",
    "1. Run Cell 1 â†’ Check GPU\n",
    "2. Run Cell 2 â†’ Install (then restart!)\n",
    "3. Run Cell 1 again â†’ Verify GPU\n",
    "4. Run Cell 3 â†’ Test IgFold\n",
    "5. Choose:\n",
    "   - **Option A (Cell 6)**: Validate custom sequences\n",
    "   - **Option B (Cells 7a-7d)**: Upload model and generate\n",
    "6. Run Cell 8 â†’ Download all PDB files\n",
    "\n",
    "**View structures:**\n",
    "- Online: https://www.rcsb.org/3d-view\n",
    "- PyMOL: `pymol antibody_000.pdb`\n",
    "- ChimeraX: https://www.cgl.ucsf.edu/chimerax/\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
